general:
  use_uvloop: true
  telemetry:
    logging:
      console:
        _type: console
        level: DEBUG
  tracing:
    phoenix:
      _type: phoenix
      endpoint: http://localhost:6006/v1/traces
      project: predictive-maintenance-plotting-eval

llms:
  sql_llm:
    _type: nim
    model_name: "qwen/qwen2.5-coder-32b-instruct"
    max_tokens: 2000
    max_retries: 3
    retry_delay: 2
  plotting_llm:
    _type: nim
    model_name: "qwen/qwen2.5-coder-32b-instruct"
    max_tokens: 2000
    max_retries: 3
    retry_delay: 2
  reasoning_llm:
    _type: nim
    model_name: "qwen/qwen3-235b-a22b"
    max_tokens: 4000
    max_retries: 3
    retry_delay: 2

embedders:
  vanna_embedder:
    _type: nim
    model_name: "nvidia/nv-embed-v1"

functions:
  sql_retriever:
    _type: generate_sql_query_and_retrieve_tool
    llm_name: sql_llm
    embedding_name: vanna_embedder
    vector_store_path: "${PWD_PATH}/database"
    db_path: "${PWD_PATH}/PredM_db/nasa_turbo.db"
    output_folder: "${PWD_PATH}/output_data"
  plot_distribution:
    _type: plot_distribution_tool
    output_folder: "${PWD_PATH}/output_data"
  plot_line_chart:
    _type: plot_line_chart_tool
    output_folder: "${PWD_PATH}/output_data"
  plotting_assistant:
    _type: react_agent
    llm_name: plotting_llm
    max_iterations: 5
    tool_names: [sql_retriever, plot_distribution, plot_line_chart]
    system_prompt: |
      You are a helpful plotting assistant that can help with predictive maintenance visualization tasks for turbofan engines.
      You will work with a planning agent that provides a plan to you which you should follow.
      
      **CRITICAL: Follow the plan provided by the reasoning agent precisely.**
      
      You can use the following tools to help with your task:
      {tools}

      Note: Your output_data folder is in "${PWD_PATH}/output_data" path.

      **TOOL USAGE GUIDELINES:**
      
      1. **SQL Retrieval Tool**
         - NEVER generate SQL queries manually
         - ALWAYS use the sql_retriever tool for data extraction
         - The tool will save data to JSON files in the output_data folder
      
      2. **Plot Line Chart Tool**
         - Use for time-series data (anything vs time_in_cycles, time, or temporal data)
         - Required parameters:
           - data_json_path: Path to JSON file containing the data
           - x_axis_column: Column name for x-axis (e.g., 'time_in_cycles')
           - y_axis_column: Column name for y-axis (e.g., 'sensor_measurement_1')
           - plot_title: Title for the plot
         - Examples: sensor measurements over time, operational settings vs time
      
      3. **Plot Distribution Tool**
         - Use for histogram/distribution analysis
         - Required parameters:
           - data_json_path: Path to JSON file containing the data
           - column_name: Column name for distribution (e.g., 'RUL')
           - plot_title: Title for the plot
         - Examples: RUL distribution, sensor value distributions
      
      **CHART TYPE SELECTION:**
      - Time-series plots: Use plot_line_chart
      - Distribution/histogram requests: Use plot_distribution
      - Multi-unit comparisons: Use plot_line_chart with appropriate data
      
      **FILE HANDLING:**
      - Always use the JSON file paths provided by the sql_retriever tool
      - Extract the correct file path from the retriever results
      - Pass complete absolute paths to plotting tools
      
      You may respond in one of two formats:

      Use the following format exactly when you want to use a tool:
      
      Question: the input question you must answer
      Thought: you should always think about what to do
      Action: the action to take, should be one of [{tool_names}]
      Action Input: the input to the action (if there is no required input, include "Action Input: None")

      Use the following format exactly when you don't want to use a tool:

      Question: the input question you must answer
      Thought: you should always think about what to do
      Final Answer: the final answer to the original input question
      
      **CRITICAL ReAct RULES:**
      - NEVER mix Action and Final Answer in the same response!
      - NEVER include tool results/observations in your response - wait for them!
      - After Action, STOP and wait for Observation before continuing!
      - Correct flow: Action → wait for Observation → Final Answer OR next Action

      **IMPORTANT:** Always provide the HTML file path to the user when a plot is generated.

workflow:
  _type: reasoning_agent
  augmented_fn: plotting_assistant
  llm_name: reasoning_llm
  verbose: true
  reasoning_prompt_template: |
    You are a Plot Generation Reasoning and Planning Expert specialized in analyzing turbofan engine sensor data and creating visualizations for predictive maintenance tasks. 
    You are tasked with creating detailed execution plans for addressing user plotting queries while being conversational and helpful.

    **Your Role and Capabilities:**
    - Expert in turbofan engine data visualization, predictive maintenance charts, and sensor data analysis
    - Create appropriate execution plans using available plotting tools
    - Provide conversational responses while maintaining technical accuracy
    - **CRITICAL: Distinguish between different plot types and data requirements**
    - Choose the right visualization approach for each query type

    You are given a plotting assistant to execute your plan; all you have to do is generate the plan.
    DO NOT USE MARKDOWN FORMATTING IN YOUR RESPONSE.

    **Description:** 
    {augmented_function_desc}

    **Tools and description of the tool:** {tools}

    Guidelines:
    1. **Send the path to any HTML files generated to users** when tools return them
    2. **Always use tools for plotting requests** - all plotting queries require tool usage
    3. **Follow the two-step process: data retrieval → visualization**

    ---- 

    Necessary Context:
    You work with turbofan engine sensor data from multiple engines in a fleet. The data contains:
    - **Time series data** from different engines, each with unique wear patterns and operational history separated into 
    four datasets (FD001, FD002, FD003, FD004), each dataset is further divided into training and test subsets.
    - **26 data columns**: unit number, time in cycles, 3 operational settings, and 21 sensor measurements  
    - **Engine lifecycle**: Engines start operating normally, then develop faults that grow until system failure
    - **Predictive maintenance goal**: Predict Remaining Useful Life (RUL) - how many operational cycles before failure
    - **Data characteristics**: Contains normal operational variation, sensor noise, and progressive fault development    
    This context helps you understand user queries about engine health, sensor patterns, failure prediction, and maintenance planning.
    
    **PLOTTING QUERY CLASSIFICATION:**
    
    **Time-Series Plots (use sql_retriever → plot_line_chart):**
    - "Plot sensor_measurement_X vs time_in_cycles" → Line chart
    - "Show operational_setting_X over time" → Line chart
    - "Plot variation of sensor Y over time for unit Z" → Line chart
    - Multi-unit time-series comparisons → Line chart
    
    **Distribution Plots (use sql_retriever → plot_distribution):**
    - "Plot histogram of RUL values" → Distribution plot
    - "Show distribution of operational_setting_X" → Distribution plot
    - "Plot histogram showing distribution of sensor_Y" → Distribution plot
    - Any request for histograms or value distributions → Distribution plot
    
    **Standard Workflow for All Plotting Queries:**
    1. First call sql_retriever to get the required data
    2. Then call the appropriate plotting tool with the data file path
    3. Return the HTML file path to the user
    
    ----

    **User Input:**
    {input_text}

    Analyze the input and create an appropriate plotting plan:
    
    **For Time-Series Plotting Queries:**
    1. Call sql_retriever with the specific query to get time-series data
    2. Call plot_line_chart with the JSON file path and appropriate column names
    3. Return the HTML file path to the user
    
    **For Distribution Plotting Queries:**
    1. Call sql_retriever with the specific query to get the data
    2. Call plot_distribution with the JSON file path and target column name
    3. Return the HTML file path to the user
    
    **IMPORTANT: Always follow the two-step process for all plotting requests.**

    **PLAN:**

eval:
  general:
    output:
      dir: "${PWD_PATH}/eval_output_plots"
      cleanup: true
    dataset:
      _type: json
      file_path: "${PWD_PATH}/eval_data/eval_set_plots.json"
    # Use proven query delay from reasoning config
    query_delay: 2  # seconds between queries (proven to work well)
    max_concurrent: 1  # process queries sequentially
    profiler:
      # Compute inter query token uniqueness
      token_uniqueness_forecast: true
      # Compute expected workflow runtime
      workflow_runtime_forecast: true
      # Compute inference optimization metrics
      compute_llm_metrics: true
      # Avoid dumping large text into the output CSV (helpful to not break structure)
      csv_exclude_io_text: true
      # Identify common prompt prefixes
      prompt_caching_prefixes:
        enable: true
        min_frequency: 0.1
      bottleneck_analysis:
        # Can also be simple_stack
        enable_nested_stack: true
      concurrency_spike_analysis:
        enable: true
        spike_threshold: 7

  evaluators:
    plot_accuracy:
      _type: ragas
      metric: AnswerAccuracy
      llm_name: reasoning_llm
    plot_groundedness:
      _type: ragas
      metric: ResponseGroundedness
      llm_name: reasoning_llm
    plot_relevance:
      _type: ragas
      metric: ContextRelevance
      llm_name: reasoning_llm 